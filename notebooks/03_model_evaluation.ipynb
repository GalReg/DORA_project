{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import joblib\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "# Загрузка тестовых данных\n",
        "test = pd.read_csv('../data/processed/test.csv')\n",
        "X_test = test.drop('PurchaseStatus', axis=1)\n",
        "y_test = test['PurchaseStatus']\n",
        "\n",
        "# Загрузка моделей\n",
        "models = {\n",
        "    'RandomForest': joblib.load('../models/rf_model_v1.pkl'),\n",
        "    'GradientBoosting': joblib.load('../models/gb_model_v1.pkl'),\n",
        "    'SVM': joblib.load('../models/svm_model_v1.pkl')\n",
        "}\n",
        "\n",
        "# Сравнение метрик\n",
        "results = []\n",
        "for name, model in models.items():\n",
        "    y_pred = model.predict(X_test)\n",
        "    results.append({\n",
        "        'Model': name,\n",
        "        'Accuracy': accuracy_score(y_test, y_pred),\n",
        "        'F1-Score': f1_score(y_test, y_pred)\n",
        "    })\n",
        "\n",
        "# Сохранение отчета\n",
        "report_df = pd.DataFrame(results)\n",
        "report_df.to_markdown('../reports/model_comparison.md', index=False)"
      ],
      "metadata": {
        "id": "8LZyYZCwjh-z"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hqTcpLNdncg9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}